
# PMLDL Project Deliverable D1.3

**Student:** Dmitry Podpryatov  
  
**Group:** DS-02  

**Project:** Music Generation (Genre Mixing)

[GitHub Repository](https://github.com/DmitryPodpryatov/PMLDL-project/)

## Progress

Since the last time, I made a decision to generate the model from the audio file only.
The decision is motivated by several reasons.
Firstly, the music datasets sorted by genres are either in MIDI or paid/hard to obtain.
This implies that either I should collect the data by myself, which is fine, but time-consuming.
Secondly, the frequency representation of the audio track is much simpler to work with, as well as it is more natural
to generate music based on music and not by reading 120 instruments note by note.

That way, the progress would be much faster.
In fact, I started training models and experimenting with parameters.
I stuck to the GTZAN dataset, which has several nice properties, such as having all songs of around 30 seconds long plus 
the sample rate is the same.

Disco and rock should work as the baseline for the generation, and now I am trying to figure out the best way to feed the 
sequence to the recurrent model.
I started from the LSTM, which should be fine, considering that there are 600k values in the 30s track.
So, to get a second of new music, I have to generate 20k data points.

## References

* [GTZAN Dataset](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification)
